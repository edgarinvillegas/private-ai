{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6 \"Differential Privacy for Deep Learning\" project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario description \n",
    "\n",
    "\n",
    "Simple project with toy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project implementation\n",
    "\n",
    "This project will use the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c8e757e9b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "priest = sy.VirtualWorker(hook, id=\"priest\")\n",
    "bob.clear_objects()\n",
    "alice.clear_objects()\n",
    "priest.clear_objects()\n",
    "th.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# A Toy Dataset\n",
    "#raw_data = th.tensor([[5.,3],[0,8],[9,0],[4,4], [2, 10], [6, 6], [3, 5], [10, 2]])\n",
    "#raw_target = th.tensor([[15.],[10], [20], [14], [16], [20], [13], [24]])\n",
    "raw_data = th.rand(1000, 2) * 10\n",
    "\n",
    "def get_synthetic_target(t):\n",
    "    return t.mm( th.tensor([[2.], [1]]) ) - 0\n",
    "\n",
    "\n",
    "raw_target = get_synthetic_target(raw_data)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(t):    \n",
    "    return t #/ 15\n",
    "\n",
    "def normalize_target(t):\n",
    "    return t #/ 42\n",
    "\n",
    "def denormalize_data(t):\n",
    "    return t #* 15\n",
    "\n",
    "def denormalize_target(t):\n",
    "    return t #* 42\n",
    "\n",
    "data = raw_data.clone().detach().requires_grad_(True)\n",
    "target = raw_target.clone().detach().requires_grad_(True)\n",
    "\n",
    "#print(data)\n",
    "#print(target)\n",
    "\n",
    "\n",
    "\n",
    "#data = th.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
    "#target = th.tensor([[2.],[0], [1], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VirtualWorker id:me #objects:0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_bob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-49346b51c7ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_bob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_bob' is not defined"
     ]
    }
   ],
   "source": [
    "print(raw_data.owner)\n",
    "print(data_bob.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(250010.9531)\n",
      "tensor(15128.1572)\n",
      "tensor(3650.8193)\n",
      "tensor(2259.9302)\n",
      "tensor(1576.2091)\n",
      "tensor(1111.1749)\n",
      "tensor(786.9075)\n",
      "tensor(560.4239)\n",
      "tensor(402.2028)\n",
      "tensor(291.6508)\n",
      "tensor(214.3882)\n",
      "tensor(160.3725)\n",
      "tensor(122.5914)\n",
      "tensor(96.1474)\n",
      "tensor(77.6209)\n",
      "tensor(64.6238)\n",
      "tensor(55.4885)\n",
      "tensor(49.0499)\n",
      "tensor(44.4951)\n",
      "tensor(41.2562)\n",
      "OrderedDict([('weight', tensor([[1.9423, 0.9749]])), ('bias', tensor([0.4854]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0694)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "opt = optim.SGD(params=model.parameters(), lr=0.00001)\n",
    "\n",
    "def train(iterations=20):\n",
    "    for iter in range(iterations):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        pred = model(data)\n",
    "\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        print(loss.data)\n",
    "        \n",
    "train()\n",
    "\n",
    "print(model.state_dict())\n",
    "\n",
    "with th.no_grad():\n",
    "    prediction = model.forward(data)\n",
    "    # print(denormalize_target(prediction))\n",
    "    diff = prediction - target\n",
    "diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = range(len(data)//2)\n",
    "second_half = range(len(data)//2, len(data))\n",
    "\n",
    "data_bob = data[first_half].send(bob)\n",
    "target_bob = target[first_half].send(bob)\n",
    "\n",
    "data_alice = data[second_half].send(alice)\n",
    "target_alice = target[second_half].send(alice)\n",
    "\n",
    "datasets = [(data_bob, target_bob), (data_alice, target_alice)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(127149.3672, requires_grad=True)\n",
      "tensor(24089.0430, requires_grad=True)\n",
      "tensor(6147.5425, requires_grad=True)\n",
      "tensor(3033.6160, requires_grad=True)\n",
      "tensor(2333.1245, requires_grad=True)\n",
      "tensor(1800.7125, requires_grad=True)\n",
      "tensor(1613.3805, requires_grad=True)\n",
      "tensor(1271.3636, requires_grad=True)\n",
      "tensor(1148.0380, requires_grad=True)\n",
      "tensor(905.3860, requires_grad=True)\n",
      "tensor(818.4637, requires_grad=True)\n",
      "tensor(646.0646, requires_grad=True)\n",
      "tensor(584.5072, requires_grad=True)\n",
      "tensor(462.0673, requires_grad=True)\n",
      "tensor(418.4362, requires_grad=True)\n",
      "tensor(331.4944, requires_grad=True)\n",
      "tensor(300.5492, requires_grad=True)\n",
      "tensor(238.8286, requires_grad=True)\n",
      "tensor(216.8590, requires_grad=True)\n",
      "tensor(173.0603, requires_grad=True)\n",
      "tensor(157.4383, requires_grad=True)\n",
      "tensor(126.3779, requires_grad=True)\n",
      "tensor(115.2422, requires_grad=True)\n",
      "tensor(93.2383, requires_grad=True)\n",
      "tensor(85.2709, requires_grad=True)\n",
      "tensor(69.7077, requires_grad=True)\n",
      "tensor(63.9760, requires_grad=True)\n",
      "tensor(52.9952, requires_grad=True)\n",
      "tensor(48.8396, requires_grad=True)\n",
      "tensor(41.1202, requires_grad=True)\n",
      "tensor(38.0742, requires_grad=True)\n",
      "tensor(32.6772, requires_grad=True)\n",
      "tensor(30.4117, requires_grad=True)\n",
      "tensor(26.6694, requires_grad=True)\n",
      "tensor(24.9518, requires_grad=True)\n",
      "tensor(22.3892, requires_grad=True)\n",
      "tensor(21.0555, requires_grad=True)\n",
      "tensor(19.3345, requires_grad=True)\n",
      "tensor(18.2694, requires_grad=True)\n",
      "tensor(17.1492, requires_grad=True)\n",
      "model.parameters() OrderedDict([('weight', tensor([[2.0096, 1.0583]])), ('bias', tensor([-0.4033]))])\n",
      "prediction:  tensor([[ 2.6646],\n",
      "        [ 0.6550],\n",
      "        [ 1.6063],\n",
      "        [-0.4033]])\n",
      "actual:  tensor([[3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.]])\n",
      "test diff:  tensor([[-0.3354],\n",
      "        [-0.3450],\n",
      "        [-0.3937],\n",
      "        [-0.4033]])\n",
      "Avg diff:  tensor(-0.0585)\n",
      "Avg diff:  tensor(-0.0569)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(iterations=20):\n",
    "\n",
    "    model = nn.Linear(2,1)\n",
    "    opt = optim.SGD(params=model.parameters(), lr=0.00001)\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "        #print(iter)\n",
    "        for _data, _target in datasets:\n",
    "\n",
    "            # send model to the data\n",
    "            model = model.send(_data.location)\n",
    "\n",
    "            # do normal training\n",
    "            opt.zero_grad()\n",
    "            pred = model(_data)\n",
    "            loss = ((pred - _target)**2).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # get smarter model back\n",
    "            model = model.get()\n",
    "\n",
    "            print(loss.get())\n",
    "    \n",
    "    print('model.parameters()', model.state_dict())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        test_data = th.tensor([[1.,1],[0,1],[1,0],[0,0]])\n",
    "        #test_target = th.tensor([[5.],[3], [4], [2]])\n",
    "        test_target = get_synthetic_target(test_data)\n",
    "        \n",
    "        prediction = model.forward(test_data)\n",
    "        print('prediction: ', prediction)\n",
    "        print('actual: ', test_target)\n",
    "        diff = prediction - test_target\n",
    "        print('test diff: ', diff)\n",
    "        \n",
    "        for _data, _target in datasets:\n",
    "            model = model.send(_data.location)\n",
    "            prediction = model.forward(_data)\n",
    "            #print(prediction)\n",
    "            diff = prediction - _target\n",
    "            print('Avg diff: ', diff.get().mean())\n",
    "            model = model.get()\n",
    "    \n",
    "    return model\n",
    "train()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bob'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bob.location.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "def fed_train_models(iterations=20):\n",
    "\n",
    "    models = {\n",
    "        'bob': nn.Linear(2,1).send(bob),\n",
    "        'alice': nn.Linear(2,1).send(alice)\n",
    "    }\n",
    "    optims = {\n",
    "        'bob': optim.SGD(params=models['bob'].parameters(), lr=0.00001),\n",
    "        'alice': optim.SGD(params=models['alice'].parameters(), lr=0.00001)\n",
    "    }\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "        print(iter)\n",
    "        for _data, _target in datasets:\n",
    "            worker_id = _data.location.id\n",
    "            model = models[worker_id]\n",
    "            opt = optims[worker_id]\n",
    "            \n",
    "            #print('data location: ', _data.location.id, ' worker_id: ', worker_id)\n",
    "            \n",
    "            # do normal training\n",
    "            opt.zero_grad()            \n",
    "            pred = model(_data)\n",
    "            loss = ((pred - _target)**2).sum()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            #print('Loss: ', loss.get())\n",
    "            #print('model.parameters()', model.get().state_dict())\n",
    "            \n",
    "    return models\n",
    "        \n",
    "models = fed_train_models()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priest._objects {62417679505: tensor([[1.9397, 1.0034]]), 85681731994: tensor([0.3291]), 51156512266: Parameter containing:\n",
      "tensor([[1.9123, 0.9902]], requires_grad=True), 93104533621: Parameter containing:\n",
      "tensor([0.5635], requires_grad=True), 8243136431: Parameter containing:\n",
      "tensor([[1.9670, 1.0167]], requires_grad=True), 57408893389: Parameter containing:\n",
      "tensor([0.0947], requires_grad=True)}\n",
      "OrderedDict([('weight', tensor([[1.9397, 1.0034]])), ('bias', tensor([0.3291]))])\n"
     ]
    }
   ],
   "source": [
    "priest.clear_objects()\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def agregate_models(models):    \n",
    "    n = th.tensor(len(models)).send(priest)\n",
    "    weights = th.zeros(1, 2).send(priest)\n",
    "    biases = th.zeros(1).send(priest)\n",
    "    for i, model in enumerate(models):\n",
    "        sd = model.state_dict()\n",
    "        w = sd['weight'].move(priest)\n",
    "        #print('w.shape: ', w.shape)\n",
    "        weights += w / n\n",
    "        #print('w: ', w)\n",
    "        b = sd['bias'].move(priest)\n",
    "        #print('b.shape: ', b.shape)\n",
    "        biases += b / n\n",
    "        #print('b: ', b)\n",
    "    # return (weights, biases)\n",
    "    # Now we have averaged weights and biases\n",
    "    amodel = nn.Linear(2,1)\n",
    "    amodel.load_state_dict(OrderedDict([\n",
    "        ('weight', weights.get()),\n",
    "        ('bias', biases.get())\n",
    "    ]))\n",
    "    return amodel \n",
    "    \n",
    "#(weights, biases) = agregate_models([models['bob'], models['alice']])\n",
    "\n",
    "amodel = agregate_models([models['bob'], models['alice']])\n",
    "\n",
    "print('priest._objects', priest._objects)\n",
    "# print('weights', weights.get())\n",
    "# print('biases', biases.get())\n",
    "print(amodel.state_dict())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  tensor([[3.2722],\n",
      "        [1.3325],\n",
      "        [2.2688],\n",
      "        [0.3291]])\n",
      "actual:  tensor([[3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.]])\n",
      "test diff:  tensor([[0.2722],\n",
      "        [0.3325],\n",
      "        [0.2688],\n",
      "        [0.3291]])\n"
     ]
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    test_data = th.tensor([[1.,1],[0,1],[1,0],[0,0]])    \n",
    "    test_target = get_synthetic_target(test_data)\n",
    "    #test_data = test_data.send(bob)\n",
    "    #test_target = test_target.send(bob)\n",
    "\n",
    "    prediction = amodel.forward(test_data)#.get()    \n",
    "    diff = prediction - test_target\n",
    "    print('prediction: ', prediction)\n",
    "    print('actual: ', test_target)\n",
    "    print('test diff: ', diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
