{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6 \"Differential Privacy for Deep Learning\" project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario description \n",
    "\n",
    "\n",
    "Training set: 60000 labeled images. This will be split in 20 slices of 3000 labeled images to generate the private models.\n",
    "Test set: 10000 images.\n",
    "The test set will have 2 purposes:\n",
    " - To help measure the training accuracy (using its labels for this)\n",
    " - To act as the \"public dataset\", by ignoring its labels. This is the main purpose of the testset\n",
    " \n",
    " Steps\n",
    "\n",
    "- 1) Train the 20 private models with the trainset\n",
    "- 2) Use the 20 partner models to predict on the local dataset (the testset), generating 20 labels for each of the datapoints\n",
    "- 3) Then, for each local data point (now with 20 labels), perform a maxcount query to get the most frequent label across the 20 labels. \n",
    "- 4) Add laplacian noise to the maxcounts to make this Differentially Private to a certain epsilon/delta constraint.\n",
    "- 5) Finally, we will retrain a new model on our local dataset which now has labels (the noised ones). This will be our final \"DP\" model.\n",
    "- 5) Do the PATE analysis to find the total epsilon used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project implementation\n",
    "\n",
    "This project will use the MNIST dataset, provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torchvision.datasets as datasets\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ###transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "mnist_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mnist_trainset.train_data\n",
    "train_targets = mnist_trainset.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = mnist_testset.test_data\n",
    "test_targets = mnist_testset.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist_trainset.test_data.sum() == mnist_trainset.train_data.sum() True\n",
    "#mnist_testset.test_data.sum() == mnist_testset.train_data.sum() True\n",
    "#mnist_testset.test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Device: ', torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)                        \n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # Use GPU if it's available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device);\n",
    "        \n",
    "    def get_device(self):\n",
    "        return \"cuda\" if next(self.parameters()).is_cuda else \"cpu\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))        \n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def predict_dataset(self, dataloader):\n",
    "        model = self\n",
    "        #predictions = list()\n",
    "        predictions = torch.tensor([]).long()\n",
    "        with torch.no_grad():\n",
    "            for images, _ in dataloader:\n",
    "                images = images.to(self.get_device())\n",
    "                log_ps = model.forward(images)                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                prediction = top_class.view(top_class.shape[0])\n",
    "                #print('prediction.shape', prediction.shape)\n",
    "                predictions = torch.cat((predictions, prediction), 0)\n",
    "                #predictions.append(prediction)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def log_time_and_reset(self, start, message = \"{:.4f} seconds\"):\n",
    "        new_start = time.time()\n",
    "        #print(f\"Device = {self.get_device()}; Last train batch time: {(time.time() - start):.4f} seconds\") #Added by Edgarin        \n",
    "        #print((message + \" {:.4f} seconds\").format(new_start - start)) #Added by Edgarin\n",
    "        print((message + \" {:.0f} ms\").format((new_start - start)*1000)) #Added by Edgarin\n",
    "        return new_start\n",
    "    \n",
    "    \n",
    "    def train_and_test(self, trainloader, testloader, epochs = 1):\n",
    "        # Copied from Part 5 - Inference and Validation (Solution).ipynb\n",
    "        # Just added the cuda\n",
    "        model = self\n",
    "        \n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "        # epochs = 30  #Only thing changed from original\n",
    "        steps = 0\n",
    "\n",
    "        train_losses, test_losses = [], []\n",
    "        for e in range(epochs):\n",
    "            print('Epoch {}'.format(e+1))\n",
    "            running_loss = 0\n",
    "            b = 0\n",
    "            epoch_start = time.time()\n",
    "            start = time.time()\n",
    "            for images, labels in trainloader:                \n",
    "                print('  batch: ', b)\n",
    "                start = self.log_time_and_reset(start, \"    Get batch:\")\n",
    "                b += 1                \n",
    "                #start = time.time() #Added by Edgarin\n",
    "                images, labels = images.to(self.get_device()), labels.to(self.get_device()) # Added by Edgarin\n",
    "                start = self.log_time_and_reset(start, \"    Move to device:\")\n",
    "                # images = images.view(images.shape[0], -1)\n",
    "                optimizer.zero_grad()\n",
    "                log_ps = model.forward(images)\n",
    "                start = self.log_time_and_reset(start, \"    model.forward(): \")\n",
    "                loss = criterion(log_ps, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                start = self.log_time_and_reset(start, \"    backward and step: \")\n",
    "                running_loss += loss.item()            \n",
    "                        \n",
    "            #else:\n",
    "            print(f\"  Epoch time: {(time.time() - epoch_start):.4f} seconds\") #Added by Edgarin\n",
    "            if(False):                \n",
    "                test_loss = 0\n",
    "                accuracy = 0\n",
    "                \n",
    "                # Turn off gradients for validation, saves memory and computations                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for images, labels in testloader:\n",
    "                        start = time.time() #Added by Edgarin\n",
    "                        images, labels = images.to(self.get_device()), labels.to(self.get_device()) # Added by Edgarin\n",
    "                        # images = images.view(images.shape[0], -1)                        \n",
    "                        log_ps = model.forward(images)\n",
    "                        test_loss += criterion(log_ps, labels)\n",
    "\n",
    "                        ps = torch.exp(log_ps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    #print(f\"Device = {self.get_device()}; Last test batch time: {(time.time() - start):.4f} seconds\") #Added by Edgarin\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "                print(\"Epoch: {}/{} \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f} \".format(running_loss/len(trainloader)),\n",
    "                      \"Test Loss: {:.3f} \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=16384, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=8192, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cpu ---\n",
      "Epoch 1\n",
      "  batch:  0\n",
      "    Get batch: 3342 ms\n",
      "    Move to device: 0 ms\n",
      "    model.forward():  81 ms\n",
      "    backward and step:  71 ms\n",
      "  batch:  1\n",
      "    Get batch: 3287 ms\n",
      "    Move to device: 0 ms\n",
      "    model.forward():  82 ms\n",
      "    backward and step:  69 ms\n",
      "  batch:  2\n",
      "    Get batch: 3241 ms\n",
      "    Move to device: 0 ms\n",
      "    model.forward():  80 ms\n",
      "    backward and step:  72 ms\n",
      "  batch:  3\n",
      "    Get batch: 2144 ms\n",
      "    Move to device: 0 ms\n",
      "    model.forward():  52 ms\n",
      "    backward and step:  45 ms\n",
      "  Epoch time: 12.5660 seconds\n",
      "Device = cpu; Whole time: 12.5870 seconds\n",
      "--- cuda ---\n",
      "Epoch 1\n",
      "  batch:  0\n",
      "    Get batch: 3270 ms\n",
      "    Move to device: 20 ms\n",
      "    model.forward():  2 ms\n",
      "    backward and step:  7 ms\n",
      "  batch:  1\n",
      "    Get batch: 3318 ms\n",
      "    Move to device: 22 ms\n",
      "    model.forward():  2 ms\n",
      "    backward and step:  6 ms\n",
      "  batch:  2\n",
      "    Get batch: 3380 ms\n",
      "    Move to device: 21 ms\n",
      "    model.forward():  2 ms\n",
      "    backward and step:  9 ms\n",
      "  batch:  3\n",
      "    Get batch: 2291 ms\n",
      "    Move to device: 15 ms\n",
      "    model.forward():  3 ms\n",
      "    backward and step:  7 ms\n",
      "  Epoch time: 12.3760 seconds\n",
      "Device = cuda; Whole time: 12.3800 seconds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu', 'cuda']:  \n",
    "    print('---', device, '---')\n",
    "    ## Test training a model\n",
    "    start = time.time()\n",
    "    model1 = Classifier()\n",
    "    model1.to(device)    \n",
    "    model1.train_and_test(trainloader, testloader, 1)\n",
    "    print(f\"Device = {model1.get_device()}; Whole time: {(time.time() - start):.4f} seconds\") #Added by Edgarin\n",
    "print('done')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "img = images[0] #.view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model1.forward(img.to(model1.get_device())).cpu()\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training slice  0 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.198  Test Loss: 2.018  Test Accuracy: 0.473\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.726  Test Loss: 1.535  Test Accuracy: 0.610\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.186  Test Loss: 1.119  Test Accuracy: 0.678\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.787  Test Loss: 0.905  Test Accuracy: 0.719\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.607  Test Loss: 0.789  Test Accuracy: 0.744\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.471  Test Loss: 0.821  Test Accuracy: 0.749\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.361  Test Loss: 0.728  Test Accuracy: 0.773\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.341  Test Loss: 0.723  Test Accuracy: 0.769\n",
      "Training slice  1 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.232  Test Loss: 2.050  Test Accuracy: 0.516\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.841  Test Loss: 1.596  Test Accuracy: 0.588\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.317  Test Loss: 1.113  Test Accuracy: 0.732\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.863  Test Loss: 0.791  Test Accuracy: 0.780\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.647  Test Loss: 0.687  Test Accuracy: 0.779\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.408  Test Loss: 0.634  Test Accuracy: 0.795\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.327  Test Loss: 0.629  Test Accuracy: 0.797\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.266  Test Loss: 0.675  Test Accuracy: 0.800\n",
      "Training slice  2 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.230  Test Loss: 2.074  Test Accuracy: 0.437\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.847  Test Loss: 1.611  Test Accuracy: 0.651\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.296  Test Loss: 1.161  Test Accuracy: 0.708\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.929  Test Loss: 0.882  Test Accuracy: 0.744\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.672  Test Loss: 0.777  Test Accuracy: 0.752\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.539  Test Loss: 0.729  Test Accuracy: 0.760\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.415  Test Loss: 0.701  Test Accuracy: 0.777\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.336  Test Loss: 0.687  Test Accuracy: 0.783\n",
      "Training slice  3 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.219  Test Loss: 2.044  Test Accuracy: 0.449\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.823  Test Loss: 1.569  Test Accuracy: 0.567\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.355  Test Loss: 1.148  Test Accuracy: 0.681\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.983  Test Loss: 0.914  Test Accuracy: 0.723\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.720  Test Loss: 0.797  Test Accuracy: 0.750\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.588  Test Loss: 0.741  Test Accuracy: 0.765\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.528  Test Loss: 0.786  Test Accuracy: 0.752\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.359  Test Loss: 0.653  Test Accuracy: 0.786\n",
      "Training slice  4 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.248  Test Loss: 2.115  Test Accuracy: 0.455\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.934  Test Loss: 1.731  Test Accuracy: 0.596\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.480  Test Loss: 1.260  Test Accuracy: 0.729\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 1.063  Test Loss: 0.936  Test Accuracy: 0.753\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.755  Test Loss: 0.735  Test Accuracy: 0.788\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.601  Test Loss: 0.654  Test Accuracy: 0.797\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.459  Test Loss: 0.618  Test Accuracy: 0.810\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.396  Test Loss: 0.599  Test Accuracy: 0.810\n",
      "Training slice  5 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.232  Test Loss: 2.028  Test Accuracy: 0.505\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.759  Test Loss: 1.558  Test Accuracy: 0.581\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.277  Test Loss: 1.170  Test Accuracy: 0.703\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.860  Test Loss: 0.880  Test Accuracy: 0.734\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.655  Test Loss: 0.738  Test Accuracy: 0.788\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.449  Test Loss: 0.840  Test Accuracy: 0.743\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.372  Test Loss: 0.667  Test Accuracy: 0.791\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.274  Test Loss: 0.697  Test Accuracy: 0.797\n",
      "Training slice  6 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.211  Test Loss: 2.022  Test Accuracy: 0.425\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.791  Test Loss: 1.565  Test Accuracy: 0.552\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.307  Test Loss: 1.139  Test Accuracy: 0.745\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.883  Test Loss: 0.884  Test Accuracy: 0.766\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.600  Test Loss: 0.718  Test Accuracy: 0.789\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.476  Test Loss: 0.681  Test Accuracy: 0.804\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.352  Test Loss: 0.660  Test Accuracy: 0.810\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.302  Test Loss: 0.613  Test Accuracy: 0.821\n",
      "Training slice  7 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.210  Test Loss: 2.039  Test Accuracy: 0.443\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.800  Test Loss: 1.556  Test Accuracy: 0.579\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.225  Test Loss: 1.077  Test Accuracy: 0.723\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.846  Test Loss: 0.851  Test Accuracy: 0.728\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.594  Test Loss: 0.693  Test Accuracy: 0.802\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.443  Test Loss: 0.697  Test Accuracy: 0.772\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.334  Test Loss: 0.624  Test Accuracy: 0.814\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.305  Test Loss: 0.609  Test Accuracy: 0.820\n",
      "Training slice  8 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.248  Test Loss: 2.094  Test Accuracy: 0.574\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.857  Test Loss: 1.642  Test Accuracy: 0.600\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.373  Test Loss: 1.180  Test Accuracy: 0.690\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.985  Test Loss: 0.865  Test Accuracy: 0.771\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.651  Test Loss: 0.727  Test Accuracy: 0.774\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.551  Test Loss: 0.669  Test Accuracy: 0.786\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.393  Test Loss: 0.633  Test Accuracy: 0.800\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.361  Test Loss: 0.629  Test Accuracy: 0.791\n",
      "Training slice  9 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.206  Test Loss: 1.999  Test Accuracy: 0.511\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.757  Test Loss: 1.557  Test Accuracy: 0.616\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.248  Test Loss: 1.130  Test Accuracy: 0.662\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.862  Test Loss: 0.875  Test Accuracy: 0.733\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.667  Test Loss: 0.701  Test Accuracy: 0.782\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.470  Test Loss: 0.687  Test Accuracy: 0.768\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.378  Test Loss: 0.639  Test Accuracy: 0.795\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.345  Test Loss: 0.644  Test Accuracy: 0.798\n",
      "Training slice  10 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.230  Test Loss: 2.058  Test Accuracy: 0.308\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.833  Test Loss: 1.649  Test Accuracy: 0.569\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.405  Test Loss: 1.189  Test Accuracy: 0.707\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.974  Test Loss: 0.922  Test Accuracy: 0.731\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.707  Test Loss: 0.724  Test Accuracy: 0.786\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.577  Test Loss: 0.694  Test Accuracy: 0.795\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.425  Test Loss: 0.646  Test Accuracy: 0.806\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.306  Test Loss: 0.646  Test Accuracy: 0.815\n",
      "Training slice  11 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.228  Test Loss: 2.060  Test Accuracy: 0.312\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.877  Test Loss: 1.609  Test Accuracy: 0.587\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.352  Test Loss: 1.152  Test Accuracy: 0.707\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.880  Test Loss: 0.864  Test Accuracy: 0.742\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.625  Test Loss: 0.798  Test Accuracy: 0.755\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.481  Test Loss: 0.689  Test Accuracy: 0.782\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.393  Test Loss: 0.668  Test Accuracy: 0.773\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.316  Test Loss: 0.703  Test Accuracy: 0.781\n",
      "Training slice  12 ...\n",
      "is_cuda True\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8  Training Loss: 2.231  Test Loss: 2.065  Test Accuracy: 0.403\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.869  Test Loss: 1.655  Test Accuracy: 0.643\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.334  Test Loss: 1.216  Test Accuracy: 0.713\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.956  Test Loss: 0.918  Test Accuracy: 0.736\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.655  Test Loss: 0.776  Test Accuracy: 0.765\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.528  Test Loss: 0.733  Test Accuracy: 0.774\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.374  Test Loss: 0.752  Test Accuracy: 0.766\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.336  Test Loss: 0.696  Test Accuracy: 0.792\n",
      "Training slice  13 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.239  Test Loss: 2.108  Test Accuracy: 0.407\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.896  Test Loss: 1.682  Test Accuracy: 0.571\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.392  Test Loss: 1.181  Test Accuracy: 0.723\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.954  Test Loss: 0.845  Test Accuracy: 0.776\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.667  Test Loss: 0.740  Test Accuracy: 0.777\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.460  Test Loss: 0.667  Test Accuracy: 0.789\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.391  Test Loss: 0.619  Test Accuracy: 0.802\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.265  Test Loss: 0.598  Test Accuracy: 0.807\n",
      "Training slice  14 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.240  Test Loss: 2.095  Test Accuracy: 0.354\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.887  Test Loss: 1.714  Test Accuracy: 0.502\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.443  Test Loss: 1.269  Test Accuracy: 0.671\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 1.005  Test Loss: 0.921  Test Accuracy: 0.761\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.702  Test Loss: 0.735  Test Accuracy: 0.775\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.478  Test Loss: 0.696  Test Accuracy: 0.776\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.392  Test Loss: 0.628  Test Accuracy: 0.816\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.277  Test Loss: 0.638  Test Accuracy: 0.799\n",
      "Training slice  15 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.209  Test Loss: 2.015  Test Accuracy: 0.494\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.726  Test Loss: 1.498  Test Accuracy: 0.623\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.162  Test Loss: 1.008  Test Accuracy: 0.762\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.765  Test Loss: 0.794  Test Accuracy: 0.768\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.579  Test Loss: 0.672  Test Accuracy: 0.788\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.434  Test Loss: 0.657  Test Accuracy: 0.800\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.313  Test Loss: 0.642  Test Accuracy: 0.804\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.281  Test Loss: 0.589  Test Accuracy: 0.822\n",
      "Training slice  16 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.229  Test Loss: 2.077  Test Accuracy: 0.422\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.877  Test Loss: 1.678  Test Accuracy: 0.501\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.391  Test Loss: 1.235  Test Accuracy: 0.630\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 1.009  Test Loss: 0.923  Test Accuracy: 0.724\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.779  Test Loss: 0.785  Test Accuracy: 0.763\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.566  Test Loss: 0.686  Test Accuracy: 0.792\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.388  Test Loss: 0.720  Test Accuracy: 0.775\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.322  Test Loss: 0.622  Test Accuracy: 0.814\n",
      "Training slice  17 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.206  Test Loss: 2.092  Test Accuracy: 0.229\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.808  Test Loss: 1.721  Test Accuracy: 0.607\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.396  Test Loss: 1.345  Test Accuracy: 0.697\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.986  Test Loss: 1.015  Test Accuracy: 0.724\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.756  Test Loss: 0.823  Test Accuracy: 0.762\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.560  Test Loss: 0.743  Test Accuracy: 0.760\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.474  Test Loss: 0.684  Test Accuracy: 0.802\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.330  Test Loss: 0.631  Test Accuracy: 0.817\n",
      "Training slice  18 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.229  Test Loss: 2.085  Test Accuracy: 0.463\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.848  Test Loss: 1.694  Test Accuracy: 0.519\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.352  Test Loss: 1.276  Test Accuracy: 0.620\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 1.003  Test Loss: 0.967  Test Accuracy: 0.720\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.718  Test Loss: 0.811  Test Accuracy: 0.751\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.534  Test Loss: 0.764  Test Accuracy: 0.760\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.414  Test Loss: 0.662  Test Accuracy: 0.801\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.336  Test Loss: 0.672  Test Accuracy: 0.782\n",
      "Training slice  19 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.241  Test Loss: 2.099  Test Accuracy: 0.390\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.889  Test Loss: 1.680  Test Accuracy: 0.584\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.383  Test Loss: 1.220  Test Accuracy: 0.674\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.973  Test Loss: 0.918  Test Accuracy: 0.736\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.738  Test Loss: 0.854  Test Accuracy: 0.720\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.539  Test Loss: 0.714  Test Accuracy: 0.766\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.381  Test Loss: 0.723  Test Accuracy: 0.752\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.378  Test Loss: 0.695  Test Accuracy: 0.773\n",
      "Training slice  20 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.216  Test Loss: 2.032  Test Accuracy: 0.563\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.749  Test Loss: 1.545  Test Accuracy: 0.602\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.195  Test Loss: 1.100  Test Accuracy: 0.731\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.804  Test Loss: 0.863  Test Accuracy: 0.746\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.589  Test Loss: 0.766  Test Accuracy: 0.736\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.435  Test Loss: 0.718  Test Accuracy: 0.758\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.308  Test Loss: 0.705  Test Accuracy: 0.778\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.251  Test Loss: 0.686  Test Accuracy: 0.776\n",
      "Training slice  21 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.232  Test Loss: 2.040  Test Accuracy: 0.538\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.792  Test Loss: 1.569  Test Accuracy: 0.547\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.275  Test Loss: 1.126  Test Accuracy: 0.690\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.876  Test Loss: 0.882  Test Accuracy: 0.730\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.615  Test Loss: 0.781  Test Accuracy: 0.739\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.526  Test Loss: 0.684  Test Accuracy: 0.783\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.388  Test Loss: 0.668  Test Accuracy: 0.787\n",
      "Epoch 8\n",
      "Epoch: 8/8  Training Loss: 0.313  Test Loss: 0.731  Test Accuracy: 0.774\n",
      "Training slice  22 ...\n",
      "is_cuda True\n",
      "Epoch 1\n",
      "Epoch: 1/8  Training Loss: 2.228  Test Loss: 2.045  Test Accuracy: 0.350\n",
      "Epoch 2\n",
      "Epoch: 2/8  Training Loss: 1.853  Test Loss: 1.578  Test Accuracy: 0.587\n",
      "Epoch 3\n",
      "Epoch: 3/8  Training Loss: 1.351  Test Loss: 1.115  Test Accuracy: 0.731\n",
      "Epoch 4\n",
      "Epoch: 4/8  Training Loss: 0.910  Test Loss: 0.861  Test Accuracy: 0.733\n",
      "Epoch 5\n",
      "Epoch: 5/8  Training Loss: 0.656  Test Loss: 0.741  Test Accuracy: 0.764\n",
      "Epoch 6\n",
      "Epoch: 6/8  Training Loss: 0.501  Test Loss: 0.745  Test Accuracy: 0.761\n",
      "Epoch 7\n",
      "Epoch: 7/8  Training Loss: 0.403  Test Loss: 0.698  Test Accuracy: 0.778\n",
      "Epoch 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9607f7655a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'is_cuda'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnew_trainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_trainloader_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_trainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-57402943b778>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(self, trainloader, testloader, epochs)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Added by Edgarin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                         \u001b[1;31m# images = images.view(images.shape[0], -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pysyft-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pysyft-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pysyft-env\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import SubsetRandomSampler \n",
    "\n",
    "def get_trainloader_slice(i, slice_size):    \n",
    "    train_indices = range(int(i*slice_size), int((i+1)*slice_size))\n",
    "    trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=False, sampler=SubsetRandomSampler(train_indices))\n",
    "    return trainloader\n",
    "\n",
    "models = list()\n",
    "train_size = len(mnist_trainset)\n",
    "n_teachers = 200\n",
    "n_slices = n_teachers  #n_slices is deprecated\n",
    "slice_size = train_size / n_slices\n",
    "\n",
    "for i in range(n_slices):\n",
    "    print('Training slice ', i, '...')\n",
    "    new_model = Classifier()\n",
    "    print('is_cuda', next(new_model.parameters()).is_cuda)\n",
    "    new_trainloader = get_trainloader_slice(i, slice_size)\n",
    "    new_model.train_and_test(new_trainloader, testloader, 8)\n",
    "    models.append(new_model)    \n",
    "len(models)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_testset = len(mnist_testset)\n",
    "with torch.no_grad():    \n",
    "    private_label_matrix = torch.zeros(len(models), n_testset).long()\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        predictions = model.predict_dataset(testloader)        \n",
    "        private_label_matrix[i] = predictions\n",
    "    print(private_label_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getLaplacianNoise(sensitivity, epsilon):\n",
    "    b = sensitivity / epsilon\n",
    "    return np.random.laplace(0, b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_labels = torch.zeros(n_testset).long()\n",
    "epsilon = 0.1\n",
    "sensitivity = 1\n",
    "nondp_labels = torch.zeros(n_testset).long()\n",
    "for i in range(n_testset):\n",
    "    private_labels = private_label_matrix[:,i].bincount(minlength=10)\n",
    "    \n",
    "    # print(private_labels.tolist())\n",
    "    noised_labels = list(map(lambda l: l + getLaplacianNoise(sensitivity, epsilon)[0], private_labels.tolist()))\n",
    "  \n",
    "    dp_labels[i] = int(np.argmax(noised_labels))\n",
    "    nondp_labels[i] = int(np.argmax(private_labels.tolist()))\n",
    "\n",
    "dp_labels\n",
    "nondp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test accuracy\n",
    "equals = dp_labels == mnist_testset.targets\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))    \n",
    "print('DP model accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# mnist_testset.test_data.shape\n",
    "# torch.Size([10000, 28, 28])\n",
    "images = mnist_testset.test_data.float() / 255  # Needed for normalization\n",
    "\n",
    "dataset = TensorDataset(images, dp_labels.long())\n",
    "dploader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "dpmodel = Classifier()\n",
    "dpmodel.train_and_test(dploader, testloader, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis(\n",
    "    teacher_preds=private_label_matrix.numpy().astype(int), \n",
    "    indices=nondp_labels.numpy().astype(int), \n",
    "    noise_eps=0.001, \n",
    "    delta=1e-5,\n",
    "    moments=100\n",
    ")\n",
    "\n",
    "# assert data_dep_eps <= data_ind_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
