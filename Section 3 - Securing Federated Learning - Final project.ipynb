{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Securing Federated Learning Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Federated Learning with Additive secret sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Data Owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n",
      "WARNING:syft.workers.base:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest1 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest2 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest3 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest1 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest2 already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker priest3 already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "hook = sy.TorchHook(th)\n",
    "from torch import nn, optim\n",
    "\n",
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "\n",
    "priest1 = sy.VirtualWorker(hook, id=\"priest1\")\n",
    "priest2 = sy.VirtualWorker(hook, id=\"priest2\")\n",
    "priest3 = sy.VirtualWorker(hook, id=\"priest3\")\n",
    "\n",
    "bob.add_workers([alice, priest1, priest2, priest3])\n",
    "alice.add_workers([bob, priest1, priest2, priest3])\n",
    "\n",
    "# A Toy Dataset\n",
    "data = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = th.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "bobs_data = data[0:2].send(bob)\n",
    "bobs_target = target[0:2].send(bob)\n",
    "\n",
    "alices_data = data[2:].send(alice)\n",
    "alices_target = target[2:].send(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Send a Copy of The Model to Alice and Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train Bob's and Alice's Models (in parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(bobs_data)\n",
    "    bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(alices_data)\n",
    "    alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "    alices_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Share both updated Models for additive secret sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:priest3 #objects:0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priest1.clear_objects()\n",
    "priest2.clear_objects()\n",
    "priest3.clear_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:73212489694 -> priest1:96789671556]\n",
      "\t-> (Wrapper)>[PointerTensor | me:31658234600 -> priest2:40764897487]\n",
      "\t-> (Wrapper)>[PointerTensor | me:29072830945 -> priest3:30028538639]\n",
      "\t*crypto provider: me*\n",
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:32662826884 -> priest1:59098941984]\n",
      "\t-> (Wrapper)>[PointerTensor | me:64334101404 -> priest2:17023136159]\n",
      "\t-> (Wrapper)>[PointerTensor | me:28821802065 -> priest3:85178814038]\n",
      "\t*crypto provider: me*\n",
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:27931524655 -> priest1:9270584623]\n",
      "\t-> (Wrapper)>[PointerTensor | me:47889344334 -> priest2:17056871942]\n",
      "\t-> (Wrapper)>[PointerTensor | me:20581613220 -> priest3:20752988731]\n",
      "\t*crypto provider: me*\n",
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:22228497855 -> priest1:31632467828]\n",
      "\t-> (Wrapper)>[PointerTensor | me:41971891663 -> priest2:63277764463]\n",
      "\t-> (Wrapper)>[PointerTensor | me:98630185589 -> priest3:26958784095]\n",
      "\t*crypto provider: me*\n"
     ]
    }
   ],
   "source": [
    "alices_weight_shared = alices_model.weight.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "print(alices_weight_shared)\n",
    "bobs_weight_shared = bobs_model.weight.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "print(bobs_weight_shared)\n",
    "\n",
    "alices_bias_shared = alices_model.bias.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "print(alices_bias_shared)\n",
    "bobs_bias_shared = bobs_model.bias.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "print(bobs_bias_shared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1:  {96789671556: tensor([[3251199777952384777, 3513528718422891821]]), 59098941984: tensor([[1339530140321009906,  807749356701800276]]), 9270584623: tensor([3352514323871012274]), 31632467828: tensor([587092001470888419])}\n",
      "p2:  {40764897487: tensor([[-3030296439814996947,   953794938863176128]]), 17023136159: tensor([[ 686910726850785587, 2609267915036542742]]), 17056871942: tensor([-1209193903088709804]), 63277764463: tensor([2678707559830787976])}\n",
      "p3:  {30028538639: tensor([[ -220903338137386920, -4467323657286067796]]), 85178814038: tensor([[-2026440867171795235, -3417017271738342869]]), 20752988731: tensor([-2143320420782302468]), 26958784095: tensor([-3265799561301676487])}\n"
     ]
    }
   ],
   "source": [
    "print('p1: ', priest1._objects)\n",
    "print('p2: ', priest2._objects)\n",
    "print('p3: ', priest3._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:73212489694 -> priest1:96789671556]\n",
      "\t-> (Wrapper)>[PointerTensor | me:31658234600 -> priest2:40764897487]\n",
      "\t-> (Wrapper)>[PointerTensor | me:29072830945 -> priest3:30028538639]\n",
      "\t*crypto provider: me*\n",
      "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> (Wrapper)>[PointerTensor | me:32662826884 -> priest1:59098941984]\n",
      "\t-> (Wrapper)>[PointerTensor | me:64334101404 -> priest2:17023136159]\n",
      "\t-> (Wrapper)>[PointerTensor | me:28821802065 -> priest3:85178814038]\n",
      "\t*crypto provider: me*\n"
     ]
    }
   ],
   "source": [
    "print(alices_weight_shared)\n",
    "print(bobs_weight_shared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Average The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5840, 0.1510]])\n",
      "tensor([-0.0450])\n"
     ]
    }
   ],
   "source": [
    "with th.no_grad():\n",
    "    avg_weight = (alices_weight_shared + bobs_weight_shared).get().float_prec() / 2\n",
    "    avg_bias = (alices_bias_shared + bobs_bias_shared).get().float_prec() / 2\n",
    "    print(avg_weight)\n",
    "    print(avg_bias)\n",
    "    model.weight.set_(avg_weight)\n",
    "    model.bias.set_(avg_bias)\n",
    "    # model.weight.set_(avg_weight)\n",
    "    # model.bias.set_(avg_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Rinse and Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.0047) Alice:tensor(0.0143)\n",
      "Bob:tensor(0.0013) Alice:tensor(0.0071)\n",
      "Bob:tensor(0.0003) Alice:tensor(0.0033)\n",
      "Bob:tensor(4.9044e-05) Alice:tensor(0.0015)\n",
      "Bob:tensor(7.1462e-05) Alice:tensor(0.0007)\n",
      "Bob:tensor(0.0001) Alice:tensor(0.0003)\n",
      "Bob:tensor(0.0002) Alice:tensor(0.0002)\n",
      "Bob:tensor(0.0002) Alice:tensor(8.5088e-05)\n",
      "Bob:tensor(0.0002) Alice:tensor(4.3939e-05)\n",
      "Bob:tensor(0.0001) Alice:tensor(2.6266e-05)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "worker_iters = 5\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "\n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=0.1)\n",
    "    alices_opt = optim.SGD(params=alices_model.parameters(), lr=0.1)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "        bobs_pred = bobs_model(bobs_data)\n",
    "        bobs_loss = ((bobs_pred - bobs_target) ** 2).sum()\n",
    "        bobs_loss.backward()\n",
    "\n",
    "        bobs_opt.step()\n",
    "        bobs_loss = bobs_loss.get().data\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "        alices_pred = alices_model(alices_data)\n",
    "        alices_loss = ((alices_pred - alices_target) ** 2).sum()\n",
    "        alices_loss.backward()\n",
    "\n",
    "        alices_opt.step()\n",
    "        alices_loss = alices_loss.get().data\n",
    "\n",
    "    alices_weight_shared = alices_model.weight.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "    bobs_weight_shared = bobs_model.weight.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "    \n",
    "    alices_bias_shared = alices_model.bias.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "    bobs_bias_shared = bobs_model.bias.data.fix_prec().share(priest1, priest2, priest3).get()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        avg_weight = (alices_weight_shared + bobs_weight_shared).get().float_prec() / 2\n",
    "        avg_bias = (alices_bias_shared + bobs_bias_shared).get().float_prec() / 2        \n",
    "        model.weight.set_(avg_weight)\n",
    "        model.bias.set_(avg_bias)\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data)\n",
    "loss = ((preds - target) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0380],\n",
      "        [0.0345],\n",
      "        [0.9535],\n",
      "        [0.9500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "tensor(0.0073)\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(target)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
